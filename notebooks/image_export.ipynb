{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Export Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the kernel observatorio-ipa(Python 3.12.7) .venv/Scripts/python\n",
    "import json\n",
    "import ee\n",
    "import ee.batch\n",
    "import ee.data\n",
    "import logging\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "from gee_toolbox.gee import assets as toolbox_assets\n",
    "import sqlite3\n",
    "\n",
    "from observatorio_ipa.services import connections\n",
    "from observatorio_ipa.core.workflows import wflows_connections\n",
    "from observatorio_ipa.core import config\n",
    "from observatorio_ipa.core.defaults import *\n",
    "from observatorio_ipa.utils import dates as utils_dates\n",
    "from observatorio_ipa.services.gee import dates as gee_dates\n",
    "from observatorio_ipa.services.gee.processes import binary, merge\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general settings\n",
    "#! JS code shows: users/observatorionieves/Cuencas/Andes # Verified on 2025-06-30\n",
    "\n",
    "settings = {\n",
    "    \"user\": \"osn-imageautomation-dev@ee-observatorionieves.iam.gserviceaccount.com\",\n",
    "    \"service_credentials_file\": Path(\n",
    "        \"../secrets/ee-observatorionieves-288939dbc1cf.json\"\n",
    "    ),\n",
    "    \"monthly_assets_path\": Path(\n",
    "        \"projects/ee-observatorionieves/assets/MODIS/Andes_MCDS4S5_Yearly_Monthly\"\n",
    "    ),\n",
    "    \"monthly_image_prefix\": \"Andes_MCDS4S5_Yearly_Monthly\",\n",
    "    \"months_list\": [\"2025-06\", \"2025-07\", \"2025-08\"],\n",
    "    \"aoi_asset_path\": Path(\"projects/ee-observatorionieves/assets/Modules/Andes\"),\n",
    "    \"dem_asset_path\": Path(\n",
    "        \"projects/ee-observatorionieves/assets/Modules/DEM_SRTM_reproj_MODIS_463_Andes\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Google Earth Engine\n",
    "\n",
    "runtime_service_account = connections.GoogleServiceAccount(\n",
    "    settings[\"service_credentials_file\"].as_posix(),\n",
    ")\n",
    "connections.connect_to_gee(runtime_service_account)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from observatorio_ipa.core.workflows.images import monthly_export\n",
    "# importlib.reload(monthly_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Job in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from observatorio_ipa.utils import db\n",
    "# importlib.reload(db)\n",
    "db_path = Path(\"../db/observatorio_ipa.db\")\n",
    "db_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Job to DB\n",
    "def create_job(conn):\n",
    "    now = db.utc_now()\n",
    "    job_id = db.new_id()\n",
    "    \n",
    "    conn.execute(\n",
    "        \"\"\"INSERT INTO jobs (id, job_status, image_export_status, stats_export_status, report_status, created_at, updated_at)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "        (\n",
    "            job_id,\n",
    "            \"RUNNING\",\n",
    "            \"PENDING\",\n",
    "            \"PENDING\",\n",
    "            \"PENDING\",\n",
    "            db.datetime_to_iso(now),\n",
    "            db.datetime_to_iso(now),\n",
    "        ),\n",
    "    )\n",
    "    return job_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'job_status': 'RUNNING', 'image_export_status': 'PENDING', 'stats_export_status': 'PENDING', 'report_status': 'PENDING', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-20T23:49:04.612341+00:00'}\n"
     ]
    }
   ],
   "source": [
    "with db.db(db_path) as conn:\n",
    "    job_id = create_job(conn)\n",
    "    job = conn.execute(\"SELECT * FROM jobs WHERE id = ?\", (job_id,)).fetchone()\n",
    "    print(dict(job))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Monthly Export Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from observatorio_ipa.services.gee.exports import ExportTaskList, ExportTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_collection_path = settings[\"monthly_assets_path\"].as_posix() # type: ignore\n",
    "name_prefix = settings[\"monthly_image_prefix\"]\n",
    "aoi_path = settings[\"aoi_asset_path\"].as_posix()\n",
    "dem_path = settings[\"dem_asset_path\"].as_posix()\n",
    "months_list = settings[\"months_list\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- MOCKING EXPORT RESULTS FOR TESTING\n",
    "\n",
    "# monthly_export_proc determines the monthly images that need to be exported, creates the Snow/Cloud TAC bands and creates the\n",
    "# Export tasks.\n",
    "#! export tasks are not being started within the function but probably should be\n",
    "#! When running in automated mode export plan details will be lost since they are not being written anywhere (db)\n",
    "try:\n",
    "    # monthly_export_results = monthly_export.monthly_export_proc(\n",
    "    #     monthly_collection_path=monthly_collection_path,\n",
    "    #     aoi_path=aoi_path,\n",
    "    #     dem_path=dem_path,\n",
    "    #     name_prefix=name_prefix,\n",
    "    #     months_list=months_list,\n",
    "    # )\n",
    "\n",
    "    monthly_export_results = {\n",
    "        \"frequency\": \"monthly\",\n",
    "        \"initial_export_plan\": [\"2025-05\", \"2025-06\", \"2025-07\", \"2025-08\"],\n",
    "        \"images_pending_export\": [\"2025-06\", \"2025-07\", \"2025-08\"],\n",
    "        \"images_excluded\": [\n",
    "            {\"2025-05\": \"already exported\"},\n",
    "            {\"2025-08\": \"Current month (Terra)\"},\n",
    "        ],\n",
    "        \"images_to_export\": [\"2025-06\", \"2025-07\"],\n",
    "        \"export_tasks\": ExportTaskList(\n",
    "            [\n",
    "                ExportTask(\n",
    "                    type=\"image\",\n",
    "                    name=monthly_export._fix_name_prefix(name_prefix) + \"_2025_05\",\n",
    "                    target=\"gee\",\n",
    "                    path=monthly_collection_path,\n",
    "                    task_status=\"ALREADY_EXISTS\",\n",
    "                ),\n",
    "                ExportTask(\n",
    "                    type=\"image\",\n",
    "                    name=monthly_export._fix_name_prefix(name_prefix) + \"_2025_06\",\n",
    "                    target=\"gee\",\n",
    "                    path=monthly_collection_path,\n",
    "                    task_status=\"RUNNING\",\n",
    "                ),\n",
    "                ExportTask(\n",
    "                    type=\"image\",\n",
    "                    name=monthly_export._fix_name_prefix(name_prefix) + \"_2025_07\",\n",
    "                    target=\"gee\",\n",
    "                    path=monthly_collection_path,\n",
    "                    task_status=\"RUNNING\",\n",
    "                ),\n",
    "                ExportTask(\n",
    "                    type=\"image\",\n",
    "                    name=monthly_export._fix_name_prefix(name_prefix) + \"_2025_08\",\n",
    "                    target=\"gee\",\n",
    "                    path=monthly_collection_path,\n",
    "                    task_status=\"EXCLUDED\",\n",
    "                    error=\"Current month (Terra)\",\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    # Update Job Status in DB\n",
    "    with db.db(db_path) as conn:\n",
    "        conn.execute(\n",
    "            \"\"\"UPDATE jobs SET \n",
    "                job_status = 'FAILED', \n",
    "                error = ?,\n",
    "                updated_at = ? WHERE id = ?\"\"\",\n",
    "            (str(e),db.datetime_to_iso(db.utc_now()), job_id),\n",
    "        )\n",
    "    export_tasks = ExportTaskList([])  # No tasks to export in case of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'job_status': 'RUNNING', 'image_export_status': 'PENDING', 'stats_export_status': 'PENDING', 'report_status': 'PENDING', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-20T23:49:04.612341+00:00'}\n"
     ]
    }
   ],
   "source": [
    "with db.db(db_path) as conn:\n",
    "    job = conn.execute(\n",
    "        \"SELECT * FROM jobs WHERE id = ?\", (job_id,)\n",
    "    ).fetchone()\n",
    "    print(dict(job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frequency': 'monthly',\n",
       " 'initial_export_plan': ['2025-05', '2025-06', '2025-07', '2025-08'],\n",
       " 'images_pending_export': ['2025-06', '2025-07', '2025-08'],\n",
       " 'images_excluded': [{'2025-05': 'already exported'},\n",
       "  {'2025-08': 'Current month (Terra)'}],\n",
       " 'images_to_export': ['2025-06', '2025-07'],\n",
       " 'export_tasks': ExportList(export_tasks=[ExportTask(type=image, name=Andes_MCDS4S5_Yearly_Monthly__2025_05, target=gee, status=EXCLUDED, task_status=ALREADY_EXISTS), ExportTask(type=image, name=Andes_MCDS4S5_Yearly_Monthly__2025_06, target=gee, status=PENDING, task_status=RUNNING), ExportTask(type=image, name=Andes_MCDS4S5_Yearly_Monthly__2025_07, target=gee, status=PENDING, task_status=RUNNING), ExportTask(type=image, name=Andes_MCDS4S5_Yearly_Monthly__2025_08, target=gee, status=EXCLUDED, task_status=EXCLUDED)])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_export_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PENDING': 2, 'EXCLUDED': 2}\n",
      "(type=image, name=Andes_MCDS4S5_Yearly_Monthly__2025_05, target=gee, status=EXCLUDED, task_status=ALREADY_EXISTS)\n",
      "(type=image, name=Andes_MCDS4S5_Yearly_Monthly__2025_06, target=gee, status=PENDING, task_status=RUNNING)\n",
      "(type=image, name=Andes_MCDS4S5_Yearly_Monthly__2025_07, target=gee, status=PENDING, task_status=RUNNING)\n",
      "(type=image, name=Andes_MCDS4S5_Yearly_Monthly__2025_08, target=gee, status=EXCLUDED, task_status=EXCLUDED)\n"
     ]
    }
   ],
   "source": [
    "# Start Export tasks\n",
    "export_tasks: ExportTaskList = monthly_export_results['export_tasks']\n",
    "export_task=export_tasks.start_exports()\n",
    "print(export_task)\n",
    "print(export_tasks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Parent Job in DB (skip if DB not set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Image Export Status: RUNNING\n",
      "{'id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'job_status': 'RUNNING', 'image_export_status': 'RUNNING', 'stats_export_status': 'PENDING', 'report_status': 'PENDING', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-20T23:49:04.806846+00:00'}\n"
     ]
    }
   ],
   "source": [
    "with db.db(db_path) as conn:\n",
    "    current_job = conn.execute(\n",
    "        \"SELECT * FROM jobs WHERE id = ?\", (job_id,)\n",
    "    ).fetchone()\n",
    "\n",
    "    if current_job['job_status'] == \"FAILED\":\n",
    "        print(\"Job is already marked as FAILED.\")\n",
    "        pass\n",
    "    \n",
    "    elif current_job['image_export_status'] == \"PENDING\":\n",
    "        if len(export_tasks) == 0:\n",
    "            image_export_status = \"NOT_REQUIRED\"\n",
    "        else:\n",
    "            image_export_status = \"RUNNING\"\n",
    "        \n",
    "        print(f\"New Image Export Status: {image_export_status}\")\n",
    "    \n",
    "        conn.execute(\n",
    "            \"UPDATE jobs SET image_export_status = ?, updated_at = ? WHERE id = ?\",\n",
    "            (image_export_status, db.datetime_to_iso(db.utc_now()), job_id)\n",
    "        )\n",
    "    \n",
    "    job = conn.execute(\n",
    "        \"SELECT * FROM jobs WHERE id = ?\", (job_id,)\n",
    "    ).fetchone()\n",
    "    print(dict(job))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save export tasks to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db row state should not be the same as status from ExportTask. ExportTask.status is self calculated from task_status.\n",
    "# whereas the db state refers to the state for polling\n",
    "\n",
    "DEFAULT_POLLING_INTERVAL_SEC = 15\n",
    "\n",
    "def _make_db_export_state(export_task:ExportTask) -> str:\n",
    "    if export_task.status in [\"FAILED\"]:\n",
    "        db_state = \"FAILED\"\n",
    "    elif export_task.status in [\"PENDING\", \"UNKNOWN\"]:\n",
    "        db_state = \"RUNNING\"\n",
    "    else:\n",
    "        db_state = \"COMPLETED\"\n",
    "    return db_state\n",
    "\n",
    "\n",
    "def add_exportTask_to_db(conn: sqlite3.Connection, job_id: str, export_task: ExportTask):\n",
    "    now = db.utc_now()\n",
    "    now_iso = db.datetime_to_iso(now)\n",
    "\n",
    "    polling_state = _make_db_export_state(export_task)\n",
    "    conn.execute(\n",
    "        \"\"\"INSERT INTO exports (\n",
    "            id, job_id, state, type, name, target, path, task_id, \n",
    "            task_status, next_check_at, poll_interval_sec, \n",
    "            created_at, updated_at)\n",
    "           VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "        (\n",
    "            export_task.id,\n",
    "            job_id,\n",
    "            polling_state,\n",
    "            export_task.type,\n",
    "            export_task.name,\n",
    "            export_task.target,\n",
    "            export_task.path.as_posix(),\n",
    "            export_task.task,\n",
    "            export_task.task_status,\n",
    "            now_iso,\n",
    "            DEFAULT_POLLING_INTERVAL_SEC,\n",
    "            now_iso,\n",
    "            now_iso,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 4 export tasks into the database.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if export_tasks:\n",
    "    with db.db(db_path) as conn:\n",
    "        cur = conn.cursor()\n",
    "        try:\n",
    "            for task in export_tasks:\n",
    "                add_exportTask_to_db(conn, job_id, task)\n",
    "            print(f\"Inserted {conn.total_changes} export tasks into the database.\")\n",
    "        # Update Job Status in DB\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while inserting export tasks: {e}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick DB Cleanup\n",
    "\n",
    "# with db.db(db_path) as conn:\n",
    "#     conn.execute(\"DELETE FROM jobs WHERE id IN (SELECT id FROM jobs)\")\n",
    "#     conn.execute(\"DELETE FROM exports WHERE id IN (SELECT id FROM exports)\")\n",
    "#     remaining_jobs = conn.execute(\"SELECT COUNT(*) FROM jobs\").fetchone()[0]\n",
    "#     remaining_tasks = conn.execute(\"SELECT COUNT(*) FROM exports\").fetchone()[0]\n",
    "#     print(f\"Remaining jobs after deletion: {remaining_jobs}\")\n",
    "#     print(f\"Remaining tasks after deletion: {remaining_tasks}\")\n",
    "\n",
    "#Quick Job Exports Cleanup\n",
    "# with db.db(db_path) as conn:\n",
    "#     conn.execute(\"DELETE FROM exports WHERE job_id = ?\", (job_id,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '7ae7ff71-11fe-4e26-af51-a8cbcae36a7a', 'job_id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'state': 'COMPLETED', 'type': 'image', 'name': 'Andes_MCDS4S5_Yearly_Monthly__2025_05', 'target': 'gee', 'path': 'projects/ee-observatorionieves/assets/MODIS/Andes_MCDS4S5_Yearly_Monthly', 'task_id': None, 'task_status': 'ALREADY_EXISTS', 'error': None, 'next_check_at': '2025-08-20T23:49:04.863191+00:00', 'lease_until': None, 'poll_interval_sec': 15, 'attempts': 0, 'deadline_at': None, 'last_error': None, 'created_at': '2025-08-20T23:49:04.863191+00:00', 'updated_at': '2025-08-20T23:49:04.863191+00:00'}\n",
      "{'id': '10bcb58f-1444-43a1-8261-804c35d1eeca', 'job_id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'state': 'RUNNING', 'type': 'image', 'name': 'Andes_MCDS4S5_Yearly_Monthly__2025_06', 'target': 'gee', 'path': 'projects/ee-observatorionieves/assets/MODIS/Andes_MCDS4S5_Yearly_Monthly', 'task_id': None, 'task_status': 'RUNNING', 'error': None, 'next_check_at': '2025-08-20T23:49:04.863191+00:00', 'lease_until': None, 'poll_interval_sec': 15, 'attempts': 0, 'deadline_at': None, 'last_error': None, 'created_at': '2025-08-20T23:49:04.863191+00:00', 'updated_at': '2025-08-20T23:49:04.863191+00:00'}\n",
      "{'id': 'edbe5094-c50c-4adf-be15-dd5bba5e41a5', 'job_id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'state': 'RUNNING', 'type': 'image', 'name': 'Andes_MCDS4S5_Yearly_Monthly__2025_07', 'target': 'gee', 'path': 'projects/ee-observatorionieves/assets/MODIS/Andes_MCDS4S5_Yearly_Monthly', 'task_id': None, 'task_status': 'RUNNING', 'error': None, 'next_check_at': '2025-08-20T23:49:04.863191+00:00', 'lease_until': None, 'poll_interval_sec': 15, 'attempts': 0, 'deadline_at': None, 'last_error': None, 'created_at': '2025-08-20T23:49:04.863191+00:00', 'updated_at': '2025-08-20T23:49:04.863191+00:00'}\n",
      "{'id': 'aa6a692a-9643-41fa-961b-4b7314d5b548', 'job_id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'state': 'COMPLETED', 'type': 'image', 'name': 'Andes_MCDS4S5_Yearly_Monthly__2025_08', 'target': 'gee', 'path': 'projects/ee-observatorionieves/assets/MODIS/Andes_MCDS4S5_Yearly_Monthly', 'task_id': None, 'task_status': 'EXCLUDED', 'error': None, 'next_check_at': '2025-08-20T23:49:04.863191+00:00', 'lease_until': None, 'poll_interval_sec': 15, 'attempts': 0, 'deadline_at': None, 'last_error': None, 'created_at': '2025-08-20T23:49:04.863191+00:00', 'updated_at': '2025-08-20T23:49:04.863191+00:00'}\n"
     ]
    }
   ],
   "source": [
    "with db.db(db_path) as conn:\n",
    "    bd_task_list = conn.execute(\"SELECT * FROM exports WHERE job_id = ?\", (job_id,)).fetchall()\n",
    "for task in bd_task_list:\n",
    "    print(dict(task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Job Status after inserting Image Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_of_tasks(conn, job_id, type):\n",
    "    rows = conn.execute(\n",
    "        \"SELECT state FROM exports WHERE job_id=? AND type=?\", (job_id, type)\n",
    "    ).fetchall()\n",
    "    return [r[\"state\"] for r in rows]\n",
    "\n",
    "\n",
    "def update_job(conn, job_id):\n",
    "    now_iso = db.datetime_to_iso(db.utc_now())\n",
    "\n",
    "    # Exit if job is not RUNNING - Assumes Nothing to Update\n",
    "    job = conn.execute(\"SELECT * FROM jobs WHERE id=?\", (job_id,)).fetchone()\n",
    "    if job[\"job_status\"] != \"RUNNING\":\n",
    "        return # Do Nothing\n",
    "\n",
    "    # ---------- IMAGE_EXPORT_STATUS ----------\n",
    "    image_states = get_state_of_tasks(conn, job_id, \"image\")\n",
    "    match job[\"image_export_status\"]:\n",
    "        case \"NOT_REQUIRED\":\n",
    "            if not image_states:\n",
    "                # Normal: No image export required/Expected - Move on to stats assessment\n",
    "               pass\n",
    "            elif all(s != \"RUNNING\" for s in image_states):\n",
    "                # Not Normal - Export tasks might have been created but failed to update Job Status\n",
    "                error_message = (\n",
    "                    \"No image exports were expected but export tasks were created.\"\n",
    "                )\n",
    "                conn.execute(\n",
    "                    \"\"\"UPDATE jobs SET job_status='FAILED', image_export_status='FAILED',\n",
    "                    error=?, updated_at=? WHERE id=?\"\"\",\n",
    "                    (error_message, now_iso, job_id),\n",
    "                )\n",
    "                return\n",
    "            else:\n",
    "                # Not Normal: Same as above but giving time to complete exports before reporting\n",
    "                return\n",
    "\n",
    "        case \"PENDING\":\n",
    "            if not image_states:\n",
    "                # Normal - Might still be waiting to create Image Export Tasks\n",
    "                # ! Add logic for deadline (Pending over x days)\n",
    "                return\n",
    "\n",
    "            elif all(s != \"RUNNING\" for s in image_states):\n",
    "                # Not Normal - Export tasks might have been created but failed to update Job Status and never changed to \"RUNNING\"\n",
    "                error_message = \"Cannot verify all exports were created/completed successfully\"\n",
    "                conn.execute(\n",
    "                    \"\"\"UPDATE jobs SET job_status='FAILED', image_export_status='FAILED',\n",
    "                    error=?, updated_at=? WHERE id=?\"\"\",\n",
    "                    (error_message, now_iso, job_id),\n",
    "                )\n",
    "                return\n",
    "            else:\n",
    "                # Not Normal: Same as above but giving time to complete exports before reporting\n",
    "                return\n",
    "\n",
    "        case \"RUNNING\":\n",
    "            if not image_states:\n",
    "                # Not Normal: If image_export_status = RUNNING, at least 1 image export should be present\n",
    "                error_message = \"Image tasks failed to create or could not be saved to DB. Check logs for details.\"\n",
    "                conn.execute(\n",
    "                    \"\"\"UPDATE jobs SET job_status='FAILED', image_export_status='FAILED', \n",
    "                   error=?, updated_at=? WHERE id=?\"\"\",\n",
    "                    (error_message, now_iso, job_id),\n",
    "                )\n",
    "                return\n",
    "\n",
    "            elif all(s != \"RUNNING\" for s in image_states):\n",
    "                # Normal: All image export tasks have now completed\n",
    "                conn.execute(\n",
    "                    \"\"\"UPDATE jobs SET image_export_status='COMPLETED', \n",
    "                    updated_at=? WHERE id=?\"\"\",\n",
    "                    (now_iso, job_id),\n",
    "            )\n",
    "            else:\n",
    "                # Normal: 1+ exports are still running - No change - keep \"RUNNING\" state\n",
    "                return\n",
    "\n",
    "        case \"FAILED\":\n",
    "            if not image_states or all(s != \"RUNNING\" for s in image_states):\n",
    "                # Not Normal: Something went wrong somewhere - Unknown error\n",
    "                error_message = job['error'] or \"Unknown error - Something went wrong somewhere - check the logs.\"\n",
    "                conn.execute(\n",
    "                    \"\"\"UPDATE jobs SET job_status='FAILED',\n",
    "                    error=?, updated_at=? WHERE id=?\"\"\",\n",
    "                    (error_message, now_iso, job_id),\n",
    "                )\n",
    "                return\n",
    "            else :\n",
    "                # Not Normal: Something went wrong somewhere - but keep \"RUNNING\" state until tasks complete\n",
    "                return\n",
    "        case \"COMPLETED\":\n",
    "            if not image_states or all(s == \"RUNNING\" for s in image_states):\n",
    "                # Not Normal: Not expecting to still be 'RUNNING' exports if image_export_status is COMPLETED\n",
    "                # revert to \"RUNNING\" stats has not Ran\n",
    "                if job[\"stats_export_status\"] in (\"NOT_REQUIRED\", \"PENDING\",):\n",
    "                    conn.execute(\n",
    "                        \"\"\"UPDATE jobs SET image_export_status='RUNNING', updated_at=? WHERE id=?\"\"\",\n",
    "                        (now_iso, job_id),\n",
    "                    )\n",
    "                return\n",
    "            else:\n",
    "                # Normal: Continue to stats status assessment\n",
    "                pass\n",
    "\n",
    "    # ---------- STATS_EXPORT_STATUS ----------\n",
    "    # Sanity check in case I missed something above\n",
    "    if job[\"image_export_status\"] not in (\"NOT_REQUIRED\", \"COMPLETED\"):\n",
    "        return\n",
    "\n",
    "    table_states = get_state_of_tasks(conn, job_id, \"table\")\n",
    "    match job[\"stats_export_status\"]:\n",
    "        case \"NOT_REQUIRED\":\n",
    "            if not table_states:\n",
    "                # Normal: No table export required/Expected - Shouldn't have come this far though\n",
    "                conn.execute(\n",
    "                    \"\"\"UPDATE jobs SET job_status='COMPLETED', updated_at=? WHERE id=?\"\"\",\n",
    "                    (now_iso, job_id),\n",
    "                )\n",
    "                return\n",
    "            elif all(s != \"RUNNING\" for s in table_states):\n",
    "                # Not Normal - Export tasks might have been created but failed to update Job Status\n",
    "                error_message = (\n",
    "                    \"No Stats exports were expected but export tasks were created.\"\n",
    "                )\n",
    "                conn.execute(\n",
    "                    \"\"\"UPDATE jobs SET job_status='FAILED', stats_export_status='FAILED',\n",
    "                    error=?, updated_at=? WHERE id=?\"\"\",\n",
    "                    (error_message, now_iso, job_id),\n",
    "                )\n",
    "                return\n",
    "            else:\n",
    "                # Not Normal: Same as above but giving time to complete exports before reporting\n",
    "                return\n",
    "\n",
    "        case \"PENDING\":\n",
    "            if not table_states:\n",
    "                # Normal - Might still be waiting to create Stats Export Tasks\n",
    "                # ! Add logic for deadline (Pending over x days)\n",
    "                return\n",
    "\n",
    "            elif all(s != \"RUNNING\" for s in table_states):\n",
    "                # Not Normal - Export tasks might have been created but failed to update Job Status and never changed to \"RUNNING\"\n",
    "                error_message = (\n",
    "                    \"Cannot verify all exports were created/completed successfully\"\n",
    "                )\n",
    "                conn.execute(\n",
    "                    \"\"\"UPDATE jobs SET job_status='FAILED', stats_export_status='FAILED',\n",
    "                    error=?, updated_at=? WHERE id=?\"\"\",\n",
    "                    (error_message, now_iso, job_id),\n",
    "                )\n",
    "                return\n",
    "            else:\n",
    "                # Not Normal: Same as above but giving time to complete exports before reporting\n",
    "                return\n",
    "\n",
    "        case \"RUNNING\":\n",
    "            if not table_states:\n",
    "                # Not Normal: If stats_export_status = RUNNING, at least 1 stats export should be present\n",
    "                error_message = \"Stats tasks failed to create or could not be saved to DB. Check logs for details.\"\n",
    "                conn.execute(\n",
    "                    \"\"\"UPDATE jobs SET job_status='FAILED', stats_export_status='FAILED', \n",
    "                    error=?, updated_at=? WHERE id=?\"\"\",\n",
    "                    (error_message, now_iso, job_id),\n",
    "                )\n",
    "                return\n",
    "\n",
    "            elif all(s != \"RUNNING\" for s in table_states):\n",
    "                # Normal: All stats export tasks have now completed\n",
    "                conn.execute(\n",
    "                    \"\"\"UPDATE jobs SET job_status='COMPLETED', stats_export_status='COMPLETED', \n",
    "                    updated_at=? WHERE id=?\"\"\",\n",
    "                    (now_iso, job_id),\n",
    "            )\n",
    "            else:\n",
    "                # Normal: 1+ exports are still running - No change - keep \"RUNNING\" state\n",
    "                return\n",
    "\n",
    "        case \"FAILED\":\n",
    "            if not table_states or all(s != \"RUNNING\" for s in table_states):\n",
    "                # Not Normal: Something went wrong somewhere - Unknown error\n",
    "                error_message = job['error'] or \"Unknown error - Something went wrong somewhere - check the logs.\"\n",
    "                conn.execute(\n",
    "                    \"\"\"UPDATE jobs SET job_status='FAILED',\n",
    "                    error=?, updated_at=? WHERE id=?\"\"\",\n",
    "                    (error_message, now_iso, job_id),\n",
    "                )\n",
    "                return\n",
    "            else :\n",
    "                # Not Normal: Something went wrong somewhere - but keep \"RUNNING\" state until tasks complete\n",
    "                return\n",
    "            \n",
    "        case \"COMPLETED\":\n",
    "            if not table_states or all(s == \"RUNNING\" for s in table_states):\n",
    "                # Not Normal: Not expecting to still be 'RUNNING' exports if stats_export_status is COMPLETED\n",
    "                # revert to \"RUNNING\" stats until all tasks complete if reporting has not gone out\n",
    "                if job[\"report_status\"] in (\"SKIP\", \"PENDING\",):\n",
    "                    conn.execute(\n",
    "                        \"\"\"UPDATE jobs SET stats_export_status='RUNNING', updated_at=? WHERE id=?\"\"\",\n",
    "                        (now_iso, job_id),\n",
    "                    )\n",
    "                return\n",
    "            else:\n",
    "                # Normal: Continue to reporting status assessment\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Before Job update ----\n",
      "{'id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'job_status': 'RUNNING', 'image_export_status': 'RUNNING', 'stats_export_status': 'PENDING', 'report_status': 'PENDING', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-20T23:49:04.806846+00:00'}\n",
      "{'type': 'image', 'state': 'COMPLETED', 'count': 2}\n",
      "{'type': 'image', 'state': 'RUNNING', 'count': 2}\n",
      "---- After Job update ----\n",
      "{'id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'job_status': 'RUNNING', 'image_export_status': 'RUNNING', 'stats_export_status': 'PENDING', 'report_status': 'PENDING', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-20T23:49:04.806846+00:00'}\n"
     ]
    }
   ],
   "source": [
    "with db.db(db_path) as conn:\n",
    "    print(\"---- Before Job update ----\")\n",
    "    job_before = conn.execute(\n",
    "        \"SELECT * FROM jobs WHERE id = ?\", (job_id,)\n",
    "    ).fetchone()\n",
    "    print(dict(job_before))\n",
    "    tasks_by_type_status = conn.execute(\n",
    "        \"SELECT type, state, COUNT(*) AS count FROM exports WHERE job_id = ? GROUP BY type, state\",\n",
    "        (job_id,),\n",
    "    ).fetchall()\n",
    "    for _task in tasks_by_type_status:\n",
    "        print(dict(_task))\n",
    "\n",
    "    print(\"---- After Job update ----\")\n",
    "    update_job(conn, job_id)\n",
    "    \n",
    "    job_after = conn.execute(\n",
    "        \"SELECT * FROM jobs WHERE id = ?\", (job_id,)\n",
    "    ).fetchone()\n",
    "    print(dict(job_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Job generator for status testing\n",
    "import random\n",
    "from itertools import product\n",
    "from observatorio_ipa.services.gee.exports import GEE_TASK_VALID_STATUS\n",
    "def random_task_list_generator(conn, job_id, type):\n",
    "    num_tasks = random.randint(0, 1)\n",
    "    for _ in range(num_tasks):\n",
    "        add_exportTask_to_db(conn, job_id, ExportTask(\n",
    "            type=type,\n",
    "            name=f\"test_task_{random.randint(1, 1000)}\",\n",
    "            target=\"gee\",\n",
    "            path=Path(\"projects/ee-observatorionieves/assets/MODIS/Andes_MCDS4S5_Yearly_Monthly\"),\n",
    "            task_status=random.choice(GEE_TASK_VALID_STATUS),\n",
    "        ))\n",
    "    return\n",
    "\n",
    "def random_job_generator():\n",
    "    job_options = ('RUNNING',)\n",
    "    image_options = ('PENDING', 'NOT_REQUIRED', 'RUNNING', 'COMPLETED', 'FAILED',)\n",
    "    stats_options = (\n",
    "        \"PENDING\",\n",
    "        \"NOT_REQUIRED\",\n",
    "        \"RUNNING\",\n",
    "        \"COMPLETED\",\n",
    "        \"FAILED\",\n",
    "    )\n",
    "    combinations = list(product(job_options, image_options, stats_options))\n",
    "\n",
    "    chosen_combo = random.choice(combinations)\n",
    "\n",
    "    with db.db(db_path) as conn:\n",
    "        job_id = db.new_id()\n",
    "        now = db.utc_now()\n",
    "        now_iso = db.datetime_to_iso(now)\n",
    "        conn.execute(\n",
    "            \"\"\"INSERT INTO jobs (id, job_status, image_export_status, stats_export_status, report_status, created_at, updated_at)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "            (\n",
    "                job_id,\n",
    "                chosen_combo[0],\n",
    "                chosen_combo[1],\n",
    "                chosen_combo[2],\n",
    "                \"PENDING\",\n",
    "                now_iso,\n",
    "                now_iso,\n",
    "            ),\n",
    "        )\n",
    "        random_task_list_generator(conn, job_id, \"image\")\n",
    "        random_task_list_generator(conn, job_id, \"table\")\n",
    "    return job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Before Job update ----\n",
      "{'id': 'c479ab75-6af8-4996-8638-4cda42d4002e', 'job_status': 'RUNNING', 'image_export_status': 'NOT_REQUIRED', 'stats_export_status': 'RUNNING', 'report_status': 'PENDING', 'email_to': None, 'error': None, 'created_at': '2025-08-20T22:08:40.276249+00:00', 'updated_at': '2025-08-20T22:08:40.276249+00:00'}\n",
      "---- After Job update ----\n",
      "{'id': 'c479ab75-6af8-4996-8638-4cda42d4002e', 'job_status': 'FAILED', 'image_export_status': 'NOT_REQUIRED', 'stats_export_status': 'FAILED', 'report_status': 'PENDING', 'email_to': None, 'error': 'Stats tasks failed to create or could not be saved to DB. Check logs for details.', 'created_at': '2025-08-20T22:08:40.276249+00:00', 'updated_at': '2025-08-20T22:08:40.294247+00:00'}\n"
     ]
    }
   ],
   "source": [
    "random_job_id = random_job_generator()\n",
    "with db.db(db_path) as conn:\n",
    "    print(\"---- Before Job update ----\")\n",
    "    job_before=conn.execute(\"SELECT * FROM jobs WHERE id = ?\", (random_job_id,)).fetchone()\n",
    "    print(dict(job_before))\n",
    "    tasks_by_type_status = conn.execute(\n",
    "        \"SELECT type, state, COUNT(*) AS count FROM exports WHERE job_id = ? GROUP BY type, state\", (random_job_id,)).fetchall()\n",
    "    for _task in tasks_by_type_status:\n",
    "        print(dict(_task))\n",
    "\n",
    "    print(\"---- After Job update ----\")   \n",
    "    update_job(conn, random_job_id)\n",
    "    update_job(conn, random_job_id)\n",
    "    job_after=conn.execute(\"SELECT * FROM jobs WHERE id = ?\", (random_job_id,)).fetchone()\n",
    "    print(dict(job_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polling Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check/Update Image Task Status\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running job found: eb306128-0eae-4ed8-9ea4-5c21baf1a9ec\n"
     ]
    }
   ],
   "source": [
    "# Identify running jobs \n",
    "\n",
    "# Limiting to 1 job for testing this is no\n",
    "\n",
    "with db.db(db_path) as conn:\n",
    "    running_jobs = conn.execute(\n",
    "        \"\"\"SELECT id FROM jobs WHERE job_status = 'RUNNING'\"\"\"\n",
    "    ).fetchall()\n",
    "\n",
    "    running_job = running_jobs[0] if running_jobs else None\n",
    "    if running_job:\n",
    "        running_job_id = running_job['id']\n",
    "        print(f\"Running job found: {running_job['id']}\")\n",
    "    else:\n",
    "        print(\"No running jobs found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def now_iso_plus(seconds):\n",
    "    return db.datetime_to_iso(db.utc_now() + datetime.timedelta(seconds=seconds))\n",
    "\n",
    "def dt_iso_plus(dt, seconds):\n",
    "    return db.datetime_to_iso(dt + datetime.timedelta(seconds=seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claim a batch of due tasks that are pending (not BLOCKED/COMPLETED)\n",
    "LEASE_SECONDS = 60\n",
    "MAX_BATCH_SIZE = 20 #! Check GEE to see max rate \n",
    "def lease_due_tasks(conn):\n",
    "    now = db.utc_now()\n",
    "    now_iso = db.datetime_to_iso(now)\n",
    "    # original code pulled everything with state ('PENDING','RUNNING','SUCCEEDED','FAILED','TIMED_OUT')\n",
    "    # Why is TIMED_OUT still being included?\n",
    "    conn.execute(\n",
    "        f\"\"\"\n",
    "        UPDATE exports SET lease_until = ? \n",
    "        WHERE id in (\n",
    "            SELECT id FROM exports \n",
    "            WHERE state in ('RUNNING', 'TIMED_OUT') \n",
    "                AND next_check_at <= ? \n",
    "                AND (lease_until is NULL OR lease_until <= ?)\n",
    "            LIMIT {MAX_BATCH_SIZE}\n",
    "            )\"\"\",\n",
    "        (now_iso_plus(LEASE_SECONDS), now_iso, now_iso),\n",
    "    )\n",
    "\n",
    "    #! Review, this would pull all records with lease set before this run. Leases are 60 seconds and polls will be 120 so there shouldn't be any pending leases\n",
    "    #! but, if multiple workers are running they might pull each other's leases\n",
    "    rows = conn.execute(\n",
    "        \"\"\"\n",
    "        SELECT * FROM exports \n",
    "        WHERE lease_until > ? \n",
    "            AND next_check_at <=?\n",
    "        \"\"\",\n",
    "        (now_iso, now_iso),\n",
    "    ).fetchall()\n",
    "\n",
    "    return rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = ee.batch.Task.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Task W5VNYYNMKT7RGHI5ZGLMKJ75 EXPORT_IMAGE: Andes_MCDS4S5_Yearly_Monthly_2025_07 (READY)>\n"
     ]
    }
   ],
   "source": [
    "print(my_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_task = ee.batch.Task(\n",
    "    task_id=\"W5VNYYNMKT7RGHI5ZGLMKJ75\",\n",
    "    task_type=ee.batch.Task.Type[\"EXPORT_IMAGE\"],\n",
    "    state=ee.batch.Task.State[\"READY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Task \"W5VNYYNMKT7RGHI5ZGLMKJ75\">\n"
     ]
    }
   ],
   "source": [
    "print(my_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'READY',\n",
       " 'description': 'Andes_MCDS4S5_Yearly_Monthly_2025_07',\n",
       " 'priority': 100,\n",
       " 'creation_timestamp_ms': 1755803493025,\n",
       " 'update_timestamp_ms': 1755803506030,\n",
       " 'start_timestamp_ms': 0,\n",
       " 'task_type': 'EXPORT_IMAGE',\n",
       " 'id': 'W5VNYYNMKT7RGHI5ZGLMKJ75',\n",
       " 'name': 'projects/ee-observatorionieves/operations/W5VNYYNMKT7RGHI5ZGLMKJ75'}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_task.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State.UNSUBMITTED\n",
      "State.READY\n",
      "State.RUNNING\n",
      "State.COMPLETED\n",
      "State.FAILED\n",
      "State.CANCEL_REQUESTED\n",
      "State.CANCELLED\n"
     ]
    }
   ],
   "source": [
    "for state in ee.batch.Task.State:\n",
    "    print(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_states = ee.batch.Task.State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<State.READY: 'READY'>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_states[\"READY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_state_testing() -> str:\n",
    "    # should raise an error if index is out of bounds, which is a potential state \n",
    "    random_options = (\"SUBMITTED\", \"PENDING\", \"STARTED\", \"READY\", \"RUNNING\", \"COMPLETED\", \"FAILED\", \"CANCELED\")\n",
    "    idx = random.randint(0, len(random_options) + 2)\n",
    "    try:\n",
    "        return random_options[idx]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"Random State doesn't Exist\")\n",
    "\n",
    "\n",
    "def exportTask_from_db_row(db_row):\n",
    "    try:\n",
    "        match db_row[\"type\"]:\n",
    "            case \"image\":\n",
    "                task_type = ee.batch.Task.Type[\"EXPORT_IMAGE\"]\n",
    "            case \"table\":\n",
    "                task_type = ee.batch.Task.Type[\"EXPORT_TABLE\"]\n",
    "            case _:\n",
    "                raise ValueError(f\"Unknown export type: {db_row['type']}\")\n",
    "\n",
    "        task_state = ee.batch.Task.State[db_row[\"state\"]]\n",
    "        task = ee.batch.Task(task_id=db_row[\"task_id\"], task_type=task_type, state=task_state)\n",
    "\n",
    "    except Exception as e:\n",
    "        task = None\n",
    "\n",
    "    return ExportTask(\n",
    "        type=db_row[\"type\"],\n",
    "        name=db_row[\"name\"],\n",
    "        target=db_row[\"target\"],\n",
    "        path=db_row[\"path\"],\n",
    "        task=task,\n",
    "        task_status=db_row[\"task_status\"],\n",
    "        id=db_row[\"id\"]\n",
    "    )\n",
    "\n",
    "def update_task_status(conn, db_task):\n",
    "    now = db.utc_now()\n",
    "    now_iso = db.datetime_to_iso(now)\n",
    "    next_poll_interval = db.next_backoff(db_task[\"poll_interval_sec\"])\n",
    "    next_check_at = dt_iso_plus(now, next_poll_interval)\n",
    "\n",
    "    # Only poll task status if not terminal. This is a double check in case a task with this status is provided\n",
    "    if db_task[\"state\"] in [\"COMPLETED\", \"FAILED\", \"TIMED_OUT\"]:\n",
    "        return\n",
    "\n",
    "    #! deadline_at is not set anywhere, needs review\n",
    "    if (\n",
    "        db_task[\"deadline_at\"]\n",
    "        and datetime.datetime.fromisoformat(db_task[\"deadline_at\"]) < now\n",
    "    ):\n",
    "        print(\n",
    "            f\"Task {db_task['id']} is past its deadline. updating status to TIMED_OUT\"\n",
    "        )\n",
    "\n",
    "        conn.execute(\n",
    "            \"\"\"UPDATE exports SET state = 'TIMED_OUT', updated_at=? WHERE id = ?\"\"\",\n",
    "            (now_iso, db_task[\"id\"]),\n",
    "        )\n",
    "        return \n",
    "\n",
    "    try:\n",
    "        # attempt to get new state\n",
    "        #! Replace with real GEE status query\n",
    "        export_task = exportTask_from_db_row(db_task)\n",
    "        print(export_task)\n",
    "        export_task.query_status()\n",
    "        # export_task.task_status= random_state_testing()\n",
    "        print(export_task)\n",
    "        new_export_status = export_task.status\n",
    "        new_task_status = export_task.task_status\n",
    "        new_state = _make_db_export_state(export_task)  # remote_status(db_task['task_id'])\n",
    "        print(f\"New task status: {new_export_status}, New state: {new_state}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Not Normal: Backoff if error in getting status - Try again later\n",
    "        print(\"Simulating GEE non-response\")\n",
    "        conn.execute(\n",
    "            \"\"\"UPDATE exports SET attempts=attempts+1, poll_interval_sec=?, next_check_at=?, last_error=?, updated_at=? WHERE id = ?\"\"\",\n",
    "            (\n",
    "                next_poll_interval,\n",
    "                next_check_at,\n",
    "                str(e),\n",
    "                now_iso,\n",
    "                db_task[\"id\"],\n",
    "            ),\n",
    "        )\n",
    "        return\n",
    "\n",
    "    if new_state in [\"RUNNING\"]:\n",
    "        # Normal: Backoff if task is still running - Try again later\n",
    "        conn.execute(\n",
    "            \"\"\"UPDATE exports SET state = 'RUNNING', task_status=?, poll_interval_sec=?, next_check_at=?, updated_at=? WHERE id = ?\"\"\",\n",
    "            (\n",
    "                new_task_status,\n",
    "                next_poll_interval,\n",
    "                next_check_at,\n",
    "                now_iso,\n",
    "                db_task[\"id\"],\n",
    "            ),\n",
    "        )\n",
    "    elif new_state in [\"COMPLETED\"]:\n",
    "        # Normal: Task completed successfully\n",
    "        conn.execute(\n",
    "            \"\"\"UPDATE exports SET state = 'COMPLETED', task_status=?, last_error = NULL, updated_at=? WHERE id = ?\"\"\",\n",
    "            (\n",
    "                new_task_status,\n",
    "                now_iso,\n",
    "                db_task[\"id\"],\n",
    "            ),\n",
    "        )\n",
    "    elif new_state in [\"FAILED\"]:\n",
    "        # Not Normal: Task failed - Mark as FAILED\n",
    "        #! Need to find how to get GEE Fail status\n",
    "        conn.execute(\n",
    "            \"\"\"UPDATE exports SET state = 'FAILED', task_status=?, updated_at=?, last_error = ? WHERE id = ?\"\"\",\n",
    "            (new_task_status, now_iso, \"GEE failed status\", db_task[\"id\"]),\n",
    "        )\n",
    "    else:\n",
    "        # Not Normal: Unknown state - Mark as UNKNOWN and log error\n",
    "        # Try again until we hit deadline\n",
    "        conn.execute(\n",
    "            \"\"\"UPDATE exports SET state = 'UNKNOWN', task_status=?, next_check_at=?, updated_at=?, last_error = ? WHERE id = ?\"\"\",\n",
    "            (\n",
    "                new_task_status,\n",
    "                next_check_at,\n",
    "                now_iso,\n",
    "                f\"Unknown state {new_state}\",\n",
    "                db_task[\"id\"],\n",
    "                ),\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- DUE TASKS ---------\n",
      "\n",
      "--------- UPDATED TASKS ---------\n",
      "job: d258473 task: c235f5b - FAILED - FAILED - None - 2025-08-21T19:23:57.341910+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:01:58.705215\n",
      "job: d258473 task: a9d8d06 - FAILED - FAILED - None - 2025-08-21T19:23:57.341910+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:01:58.705215\n",
      "job: d258473 task: b26d69f - FAILED - FAILED - None - 2025-08-21T19:23:57.341910+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:01:58.705215\n",
      "job: d258473 task: 057e2f1 - FAILED - FAILED - None - 2025-08-21T19:23:57.341910+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:01:58.705215\n",
      "job: d258473 task: 73cd90f - FAILED - FAILED - None - 2025-08-21T19:23:57.341910+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:01:58.705215\n",
      "job: d258473 task: 6f6b38a - FAILED - FAILED - None - 2025-08-21T19:23:57.341910+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:01:58.705215\n",
      "job: d258473 task: 3a5a62b - FAILED - FAILED - None - 2025-08-21T19:23:57.341910+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:01:58.705215\n",
      "job: d258473 task: 3ae57c5 - COMPLETED - COMPLETED - None - 2025-08-21T19:23:57.341910+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:01:58.705215\n",
      "job: d258473 task: cbec8e3 - COMPLETED - COMPLETED - None - 2025-08-21T19:23:57.341910+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:01:58.705215\n",
      "job: d258473 task: 8b92eef - COMPLETED - COMPLETED - None - 2025-08-21T19:23:57.341910+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:01:58.705215\n",
      "job: d258473 task: e7f0562 - COMPLETED - COMPLETED - None - 2025-08-21T20:11:59.764651+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:50:01.127956\n",
      "job: d258473 task: c5b706a - COMPLETED - COMPLETED - None - 2025-08-21T20:18:53.842904+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:56:55.206209\n",
      "job: d258473 task: 78321c8 - COMPLETED - COMPLETED - None - 2025-08-21T20:19:16.156054+00:00 - 2025-08-22 01:21:58.636695+00:00 - -1 day, 18:57:17.519359\n",
      "job: d258473 task: 7197514 - RUNNING - RUNNING - name 'ExportTask' is not defined - 2025-08-22T01:25:38.310971+00:00 - 2025-08-22 01:21:58.636695+00:00 - 0:03:39.674276\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate over each due task\n",
    "with db.db(db_path) as conn:\n",
    "    due_tasks = lease_due_tasks(conn)\n",
    "    print(\"--------- DUE TASKS ---------\")\n",
    "    for db_task in due_tasks:\n",
    "        print(\n",
    "            f\"task: {db_task['id']} - {db_task['state']} - {db_task['task_status']} - {db_task['last_error']} - {db_task['next_check_at']} - {db.utc_now()}\"\n",
    "        )\n",
    "        update_task_status(conn, db_task)\n",
    "    print()\n",
    "\n",
    "    print(\"--------- UPDATED TASKS ---------\")\n",
    "    updated_tasks = conn.execute(\n",
    "        \"\"\"\n",
    "        SELECT a.id AS job_id, b.* \n",
    "        FROM jobs AS a \n",
    "            JOIN exports AS b ON a.id = b.job_id \n",
    "        WHERE a.job_status='RUNNING'\n",
    "        ORDER BY next_check_at\"\"\").fetchall()\n",
    "    for task in updated_tasks:\n",
    "        time_until_next_check = datetime.datetime.fromisoformat(task['next_check_at']) - db.utc_now()\n",
    "        print(f\"job: {task['job_id'][0:7]} task: {task['id'][0:7]} - {task['state']} - {task['task_status']} - {task['last_error']} - {task['next_check_at']} - {db.utc_now()} - {time_until_next_check}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESET task for testing\n",
    "# with db.db(db_path) as conn:\n",
    "#     funky_id = \"ab5d7cff-d3d5-44ba-a85f-5fd19b03bf56\"\n",
    "#     conn.execute(\n",
    "#         \"UPDATE exports SET state = 'RUNNING', task_status='RUNNING' WHERE id = ?\",\n",
    "#         (funky_id,),\n",
    "#     )\n",
    "#     funky_task = conn.execute(\"SELECT * FROM exports WHERE id = ?\", (funky_id,)).fetchone()\n",
    "#     print(f\"Updated task: {funky_task['id']} - {funky_task['state']} - {funky_task['task_status']} - {funky_task['last_error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Job if Image Exports Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_job_details(conn, job_id):\n",
    "    job = conn.execute(\n",
    "        \"SELECT * FROM jobs WHERE id = ?\", (job_id,)\n",
    "    ).fetchone()\n",
    "    print(dict(job))\n",
    "    \n",
    "    tasks_by_type_status = conn.execute(\n",
    "        \"SELECT type, state, COUNT(*) AS count FROM exports WHERE job_id = ? GROUP BY type, state\",\n",
    "        (job_id,),\n",
    "    ).fetchall()\n",
    "    for _task in tasks_by_type_status:\n",
    "        print(dict(_task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### eb306128-0eae-4ed8-9ea4-5c21baf1a9ec #####\n",
      "---- Before Job update ----\n",
      "{'id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'job_status': 'RUNNING', 'image_export_status': 'RUNNING', 'stats_export_status': 'PENDING', 'report_status': 'PENDING', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-20T23:49:04.806846+00:00'}\n",
      "{'type': 'image', 'state': 'COMPLETED', 'count': 3}\n",
      "{'type': 'image', 'state': 'FAILED', 'count': 1}\n",
      "---- After Job update ----\n",
      "{'id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'job_status': 'RUNNING', 'image_export_status': 'COMPLETED', 'stats_export_status': 'PENDING', 'report_status': 'PENDING', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-21T00:44:42.558335+00:00'}\n",
      "{'type': 'image', 'state': 'COMPLETED', 'count': 3}\n",
      "{'type': 'image', 'state': 'FAILED', 'count': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with db.db(db_path) as conn:\n",
    "    jobs = conn.execute(\"SELECT * FROM jobs WHERE job_status IN ('RUNNING')\").fetchall()\n",
    "    for job in jobs:\n",
    "        poll_job_id = job['id']\n",
    "        print(f\"##### {poll_job_id} #####\")\n",
    "\n",
    "        print(\"---- Before Job update ----\")\n",
    "        _print_job_details(conn, poll_job_id)\n",
    "\n",
    "        update_job(conn, poll_job_id)\n",
    "\n",
    "        print(\"---- After Job update ----\")\n",
    "        _print_job_details(conn, poll_job_id)\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats Export Workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_stats_export_tasks():\n",
    "    dummy_stat_task1 = ExportTask(\n",
    "    type=\"table\",\n",
    "    name=f\"stats_task_{job_id}\",\n",
    "    target=\"gee\",\n",
    "    path=\"projects/observatorio-ipa/stats\",\n",
    "    task_status=\"RUNNING\",  # Simulating a running task\n",
    ")\n",
    "    dummy_stat_task2 = ExportTask(\n",
    "        type=\"table\",\n",
    "        name=f\"stats_task_{job_id}_2\",\n",
    "        target=\"gee\",\n",
    "        path=\"projects/observatorio-ipa/stats\",\n",
    "        task_status=\"RUNNING\",  # Simulating a running task\n",
    "    )\n",
    "\n",
    "    return ExportTaskList([dummy_stat_task1, dummy_stat_task2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_export(conn, job_id):\n",
    "    now_iso = db.datetime_to_iso(db.utc_now())\n",
    "    job = conn.execute(\"SELECT * FROM jobs WHERE id=?\", (job_id,)).fetchone()\n",
    "\n",
    "    # Skip if job is not RUNNING or image exports are not COMPLETED or stats exports is not PENDING\n",
    "    if job['job_status'] != \"RUNNING\" or job['image_export_status'] in (\"PENDING\", \"RUNNING\") or job['stats_export_status'] != \"PENDING\":\n",
    "        return\n",
    "\n",
    "    # Simulate stats export tasks creation - Replace with actual logic to create stats export tasks\n",
    "    # Logic to create Export Stats - Fake tasks for now\n",
    "    try :\n",
    "        stats_task_list = dummy_stats_export_tasks()\n",
    "        # Insert stats tasks into the database\n",
    "        for task in stats_task_list:\n",
    "            add_exportTask_to_db(conn, job_id, task)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while creating stats export tasks: {e}\")\n",
    "        conn.execute(\n",
    "            \"\"\"UPDATE jobs SET job_status='FAILED', stats_export_status='FAILED',\n",
    "            error=?, updated_at=? WHERE id=?\"\"\",\n",
    "            (str(e), now_iso, job_id),\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Update job stats_export_status to RUNNING\n",
    "    if stats_task_list:\n",
    "        new_stats_export_status = \"RUNNING\"\n",
    "    else :\n",
    "        new_stats_export_status = \"COMPLETED\"\n",
    "    conn.execute(\n",
    "        \"\"\"UPDATE jobs SET stats_export_status=?, updated_at=? WHERE id=?\"\"\",\n",
    "        (new_stats_export_status,now_iso, job_id),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### eb306128-0eae-4ed8-9ea4-5c21baf1a9ec #####\n",
      "---- Before Starting Stats ----\n",
      "{'id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'job_status': 'RUNNING', 'image_export_status': 'COMPLETED', 'stats_export_status': 'PENDING', 'report_status': 'PENDING', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-21T00:44:42.558335+00:00'}\n",
      "{'type': 'image', 'state': 'COMPLETED', 'count': 3}\n",
      "{'type': 'image', 'state': 'FAILED', 'count': 1}\n",
      "---- After Starting Stats ----\n",
      "{'id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'job_status': 'RUNNING', 'image_export_status': 'COMPLETED', 'stats_export_status': 'RUNNING', 'report_status': 'PENDING', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-21T00:45:00.121259+00:00'}\n",
      "{'type': 'image', 'state': 'COMPLETED', 'count': 3}\n",
      "{'type': 'image', 'state': 'FAILED', 'count': 1}\n",
      "{'type': 'table', 'state': 'RUNNING', 'count': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Orchestrate per job\n",
    "with db.db(db_path) as conn:\n",
    "    jobs = conn.execute(\"SELECT * FROM jobs WHERE job_status IN ('RUNNING')\").fetchall()\n",
    "    for job in jobs:\n",
    "        poll_job_id = job[\"id\"]\n",
    "        print(f\"##### {poll_job_id} #####\")\n",
    "\n",
    "        print(\"---- Before Starting Stats ----\")\n",
    "        _print_job_details(conn, poll_job_id)\n",
    "\n",
    "        stats_export(conn, poll_job_id)\n",
    "\n",
    "        print(\"---- After Starting Stats ----\")\n",
    "        _print_job_details(conn, poll_job_id)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check/Update Stats Task Status (Polling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- DUE TASKS ---------\n",
      "task: a5bfa506-518f-45b5-aac8-c4787aefb5a6 - RUNNING - PENDING - Random State doesn't Exist - 2025-08-21T00:49:49.101634+00:00 - 2025-08-21 00:50:25.734813+00:00\n",
      "(type=table, name=stats_task_eb306128-0eae-4ed8-9ea4-5c21baf1a9ec, target=gee, status=PENDING, task_status=PENDING)\n",
      "(type=table, name=stats_task_eb306128-0eae-4ed8-9ea4-5c21baf1a9ec, target=gee, status=COMPLETED, task_status=CANCELED)\n",
      "New task status: COMPLETED, New state: COMPLETED\n",
      "\n",
      "--------- UPDATED TASKS ---------\n",
      "job: eb30612 task: 7ae7ff7 - COMPLETED - ALREADY_EXISTS - None - 2025-08-20T23:49:04.863191+00:00 - 2025-08-21 00:50:25.734813+00:00 - -1 day, 22:58:39.128378\n",
      "job: eb30612 task: aa6a692 - COMPLETED - EXCLUDED - None - 2025-08-20T23:49:04.863191+00:00 - 2025-08-21 00:50:25.735813+00:00 - -1 day, 22:58:39.127378\n",
      "job: eb30612 task: 10bcb58 - COMPLETED - COMPLETED - None - 2025-08-20T23:50:33.688377+00:00 - 2025-08-21 00:50:25.735813+00:00 - -1 day, 23:00:07.952564\n",
      "job: eb30612 task: edbe509 - FAILED - FAILED - GEE failed status - 2025-08-21T00:41:38.448366+00:00 - 2025-08-21 00:50:25.735813+00:00 - -1 day, 23:51:12.712553\n",
      "job: eb30612 task: 73e99fe - FAILED - FAILED - GEE failed status - 2025-08-21T00:48:47.612042+00:00 - 2025-08-21 00:50:25.735813+00:00 - -1 day, 23:58:21.876229\n",
      "job: eb30612 task: a5bfa50 - COMPLETED - CANCELED - None - 2025-08-21T00:49:49.101634+00:00 - 2025-08-21 00:50:25.735813+00:00 - -1 day, 23:59:23.365821\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each due task\n",
    "with db.db(db_path) as conn:\n",
    "    due_tasks = lease_due_tasks(conn)\n",
    "    print(\"--------- DUE TASKS ---------\")\n",
    "    for db_task in due_tasks:\n",
    "        print(\n",
    "            f\"task: {db_task['id']} - {db_task['state']} - {db_task['task_status']} - {db_task['last_error']} - {db_task['next_check_at']} - {db.utc_now()}\"\n",
    "        )\n",
    "        update_task_status(conn, db_task)\n",
    "    print()\n",
    "\n",
    "    print(\"--------- UPDATED TASKS ---------\")\n",
    "    updated_tasks = conn.execute(\n",
    "        \"\"\"\n",
    "        SELECT a.id AS job_id, b.* \n",
    "        FROM jobs AS a \n",
    "            JOIN exports AS b ON a.id = b.job_id \n",
    "        WHERE a.job_status='RUNNING'\n",
    "        ORDER BY next_check_at\"\"\"\n",
    "    ).fetchall()\n",
    "    for task in updated_tasks:\n",
    "        time_until_next_check = (\n",
    "            datetime.datetime.fromisoformat(task[\"next_check_at\"]) - db.utc_now()\n",
    "        )\n",
    "        print(\n",
    "            f\"job: {task['job_id'][0:7]} task: {task['id'][0:7]} - {task['state']} - {task['task_status']} - {task['last_error']} - {task['next_check_at']} - {db.utc_now()} - {time_until_next_check}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Job Status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### eb306128-0eae-4ed8-9ea4-5c21baf1a9ec #####\n",
      "---- Before Job update ----\n",
      "{'id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'job_status': 'RUNNING', 'image_export_status': 'COMPLETED', 'stats_export_status': 'RUNNING', 'report_status': 'PENDING', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-21T00:45:00.121259+00:00'}\n",
      "{'type': 'image', 'state': 'COMPLETED', 'count': 3}\n",
      "{'type': 'image', 'state': 'FAILED', 'count': 1}\n",
      "{'type': 'table', 'state': 'COMPLETED', 'count': 1}\n",
      "{'type': 'table', 'state': 'FAILED', 'count': 1}\n",
      "---- After Job update ----\n",
      "{'id': 'eb306128-0eae-4ed8-9ea4-5c21baf1a9ec', 'job_status': 'COMPLETED', 'image_export_status': 'COMPLETED', 'stats_export_status': 'COMPLETED', 'report_status': 'PENDING', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-21T00:53:32.900002+00:00'}\n",
      "{'type': 'image', 'state': 'COMPLETED', 'count': 3}\n",
      "{'type': 'image', 'state': 'FAILED', 'count': 1}\n",
      "{'type': 'table', 'state': 'COMPLETED', 'count': 1}\n",
      "{'type': 'table', 'state': 'FAILED', 'count': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with db.db(db_path) as conn:\n",
    "    jobs = conn.execute(\"SELECT * FROM jobs WHERE job_status IN ('RUNNING')\").fetchall()\n",
    "    for job in jobs:\n",
    "        poll_job_id = job[\"id\"]\n",
    "        print(f\"##### {poll_job_id} #####\")\n",
    "\n",
    "        print(\"---- Before Job update ----\")\n",
    "        _print_job_details(conn, poll_job_id)\n",
    "\n",
    "        update_job(conn, poll_job_id)\n",
    "\n",
    "        print(\"---- After Job update ----\")\n",
    "        _print_job_details(conn, poll_job_id)\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job: eb30612 status: COMPLETED - task: 7ae7ff7 - COMPLETED - ALREADY_EXISTS - None - -1 day, 22:54:55.619581\n",
      "job: eb30612 status: COMPLETED - task: 10bcb58 - COMPLETED - COMPLETED - None - -1 day, 22:56:24.443768\n",
      "job: eb30612 status: COMPLETED - task: edbe509 - FAILED - FAILED - GEE failed status - -1 day, 23:47:29.203757\n",
      "job: eb30612 status: COMPLETED - task: aa6a692 - COMPLETED - EXCLUDED - None - -1 day, 22:54:55.618582\n",
      "job: eb30612 status: COMPLETED - task: a5bfa50 - COMPLETED - CANCELED - None - -1 day, 23:55:39.857025\n",
      "job: eb30612 status: COMPLETED - task: 73e99fe - FAILED - FAILED - GEE failed status - -1 day, 23:54:38.367433\n"
     ]
    }
   ],
   "source": [
    "# View state of all tasks \n",
    "with db.db(db_path) as conn:\n",
    "    updated_tasks = conn.execute(\n",
    "        \"\"\"\n",
    "        SELECT a.id AS job_id, a.job_status, b.* \n",
    "        FROM jobs AS a \n",
    "            JOIN exports AS b ON a.id = b.job_id \n",
    "        ORDER BY a.id\"\"\"\n",
    "    ).fetchall()\n",
    "    for task in updated_tasks:\n",
    "        time_until_next_check = (\n",
    "            datetime.datetime.fromisoformat(task[\"next_check_at\"]) - db.utc_now()\n",
    "        )\n",
    "        print(\n",
    "            f\"job: {task['job_id'][0:7]} status: {task['job_status']} - task: {task['id'][0:7]} - {task['state']} - {task['task_status']} - {task['last_error']} - {time_until_next_check}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_job_report(conn, job_id):\n",
    "\n",
    "    job = conn.execute(\n",
    "        \"SELECT * FROM jobs WHERE id=? LIMIT 1\", (job_id,)\n",
    "    ).fetchone()\n",
    "\n",
    "    if not (job['job_status'] in (\"COMPLETED\", \"FAILED\") and job['report_status'] in (\"PENDING\")):\n",
    "        print(f\"skipping.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Generating report for job {job_id}...\")\n",
    "    tasks = conn.execute(\n",
    "        \"SELECT * FROM exports WHERE job_id=? ORDER BY type, state\", (job_id,)\n",
    "    ).fetchall()\n",
    "\n",
    "    full_job = {\n",
    "        \"job\": dict(job),\n",
    "        \"tasks\": dict(tasks)\n",
    "    }\n",
    "    try:\n",
    "        print(dict(full_job)) #! Replace with actual report generation logic\n",
    "        conn.execute(\n",
    "            \"UPDATE jobs SET report_status='COMPLETED', updated_at=? WHERE id=?\",\n",
    "            (db.datetime_to_iso(db.utc_now()), job_id),\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error printing full job details: {e}\")\n",
    "        conn.execute(\n",
    "            \"UPDATE jobs SET report_status='FAILED', updated_at=? WHERE id=?\",\n",
    "            (db.datetime_to_iso(db.utc_now()), job_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_job(conn, job_id):\n",
    "    job = conn.execute(\n",
    "        \"SELECT * FROM jobs WHERE id = ?\", (job_id,)\n",
    "    ).fetchone()\n",
    "    job_dict = dict(job)\n",
    "    job_dict['id'] = job['id'][0:7]\n",
    "    print(job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### eb306128-0eae-4ed8-9ea4-5c21baf1a9ec #####\n",
      "---- Before Report Generation ----\n",
      "{'id': 'eb30612', 'job_status': 'COMPLETED', 'image_export_status': 'COMPLETED', 'stats_export_status': 'COMPLETED', 'report_status': 'COMPLETED', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-21T01:11:09.657679+00:00'}\n",
      "skipping.\n",
      "---- After Report Generation ----\n",
      "{'id': 'eb30612', 'job_status': 'COMPLETED', 'image_export_status': 'COMPLETED', 'stats_export_status': 'COMPLETED', 'report_status': 'COMPLETED', 'email_to': None, 'error': None, 'created_at': '2025-08-20T23:49:04.612341+00:00', 'updated_at': '2025-08-21T01:11:09.657679+00:00'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Orchestrate per job\n",
    "with db.db(db_path) as conn:\n",
    "    jobs = conn.execute(\"SELECT * FROM jobs WHERE job_status IN ('COMPLETED', 'FAILED')\").fetchall()\n",
    "    for job in jobs:\n",
    "        poll_job_id = job[\"id\"]\n",
    "        print(f\"##### {poll_job_id} #####\")\n",
    "\n",
    "        print(\"---- Before Report Generation ----\")\n",
    "        _print_job(conn, poll_job_id)\n",
    "\n",
    "        update_job_report(conn, poll_job_id)\n",
    "\n",
    "        print(\"---- After Report Generation ----\")\n",
    "        _print_job(conn, poll_job_id)\n",
    "\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "observatorio-ipa (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
